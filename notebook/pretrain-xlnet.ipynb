{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4c3bfb3f-507d-44c5-b957-8d6c0ba15623",
    "_uuid": "f4cb09e6-ce0e-4824-a0fd-5e4cc0e5da38",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:52:25.410522Z",
     "iopub.status.busy": "2022-06-10T01:52:25.409979Z",
     "iopub.status.idle": "2022-06-10T01:53:48.607598Z",
     "shell.execute_reply": "2022-06-10T01:53:48.60642Z",
     "shell.execute_reply.started": "2022-06-10T01:52:25.410422Z"
    },
    "id": "KjwVGRnxicJn",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "a846b17e-e065-4f1b-db1f-bb5a00cd6120"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers -U\n",
    "# !pip install datasets\n",
    "# !pip install nvidia-ml-py3 \n",
    "# !pip install humanize\n",
    "# !pip install torch -U \n",
    "# !pip install transformers[sentencepiece]\n",
    "# !pip install -q git+https://github.com/gmihaila/ml_things.git\n",
    "# !pip list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "cccde980-c85b-463f-8ded-7444b2c1a66c",
    "_uuid": "05bae648-5661-4bff-b324-7e49821e6135",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:53:48.610258Z",
     "iopub.status.busy": "2022-06-10T01:53:48.609875Z",
     "iopub.status.idle": "2022-06-10T01:53:48.615473Z",
     "shell.execute_reply": "2022-06-10T01:53:48.614763Z",
     "shell.execute_reply.started": "2022-06-10T01:53:48.610221Z"
    },
    "id": "3ztk5L7pbyYc",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "os.makedirs(\"my-xlnet-model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "6f263d11-992e-43dc-9807-244ebede839e",
    "_uuid": "e7a8dd23-3aa2-4c70-8947-714fb9d139be",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:53:48.61759Z",
     "iopub.status.busy": "2022-06-10T01:53:48.616651Z",
     "iopub.status.idle": "2022-06-10T01:53:48.628575Z",
     "shell.execute_reply": "2022-06-10T01:53:48.627658Z",
     "shell.execute_reply.started": "2022-06-10T01:53:48.617559Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_MODE\"] = 'offline'\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "01650df7-be98-48cf-9043-036f904f48f7",
    "_uuid": "49384049-83f6-4387-b866-90c126d88933",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:53:48.631137Z",
     "iopub.status.busy": "2022-06-10T01:53:48.630462Z",
     "iopub.status.idle": "2022-06-10T01:53:48.640915Z",
     "shell.execute_reply": "2022-06-10T01:53:48.640133Z",
     "shell.execute_reply.started": "2022-06-10T01:53:48.631103Z"
    },
    "id": "N8oJ1CRki6ul",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "paths = ['../../wiki.txt']\n",
    "# paths = ['../input/idwikitext/wiki.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b053bdfe-fcbd-4918-a694-09aebeac293f",
    "_uuid": "697daaf9-b1cc-44bb-b4c9-639fd836db36",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:53:48.643532Z",
     "iopub.status.busy": "2022-06-10T01:53:48.642272Z",
     "iopub.status.idle": "2022-06-10T01:54:13.235955Z",
     "shell.execute_reply": "2022-06-10T01:54:13.235058Z",
     "shell.execute_reply.started": "2022-06-10T01:53:48.643478Z"
    },
    "id": "4CAqQ5MViqxG",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "e83f9bb5-7bd9-41be-d133-d578b669e629"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bbccf846be071e24\n",
      "Reusing dataset text (C:\\Users\\Acer\\.cache\\huggingface\\datasets\\text\\default-bbccf846be071e24\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612da2c1bfbc4613acfa1527cd1eb278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"text\", data_files={\"train\": paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "adee2cb1-56a9-428f-aa64-beaa0ddaeb5b",
    "_uuid": "d4d77d7c-1950-40a6-aa26-914ce9bc36cb",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:54:13.238019Z",
     "iopub.status.busy": "2022-06-10T01:54:13.237445Z",
     "iopub.status.idle": "2022-06-10T01:54:13.528823Z",
     "shell.execute_reply": "2022-06-10T01:54:13.527847Z",
     "shell.execute_reply.started": "2022-06-10T01:54:13.237989Z"
    },
    "id": "lycXbUOW1PDH",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "# tokenizer = XLNetTokenizer(\n",
    "#     \"../input/spmmodel/spm.uncased.test.model\",\n",
    "#     do_lower_case=True\n",
    "# )\n",
    "tokenizer = XLNetTokenizer(\n",
    "    \"../../spm.v1.uncased.model\",\n",
    "    do_lower_case=True\n",
    ")\n",
    "# tokenizer = XLNetTokenizer.from_pretrained(\"../input/xlnet-gpu/my-xlnet-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "1b56aadc-2417-411c-bb7e-87442b815a88",
    "_uuid": "235ad27f-5772-4fd7-8447-87cbc63b39b0",
    "execution": {
     "iopub.execute_input": "2022-06-10T01:54:34.248766Z",
     "iopub.status.busy": "2022-06-10T01:54:34.248413Z",
     "iopub.status.idle": "2022-06-10T01:54:34.820856Z",
     "shell.execute_reply": "2022-06-10T01:54:34.818726Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.24873Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "9e6e6da4-d11a-44d5-8a74-62ef687527f8",
    "_uuid": "14ee73b1-ee01-4804-a47b-876f5fb81554",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.822048Z",
     "iopub.status.idle": "2022-06-10T01:54:34.82244Z",
     "shell.execute_reply": "2022-06-10T01:54:34.822267Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.822249Z"
    },
    "id": "33U_4jva1gRu",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Remove empty lines\n",
    "    examples[\"text\"] = [line for line in examples[\"text\"] if len(line) > 0 and not line.isspace()]\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "ddd24628-80d9-45a0-9b78-176921a4c1b2",
    "_uuid": "eff622d3-2687-4278-a7e0-b8c48bf1ee40",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.824503Z",
     "iopub.status.idle": "2022-06-10T01:54:34.826852Z",
     "shell.execute_reply": "2022-06-10T01:54:34.826538Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.8265Z"
    },
    "id": "lTpJky6t1hWH",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "61d0575e-366d-43b9-a7a3-f0c6c041c107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\multiprocess\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 520, in wrapper\n    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 487, in wrapper\n    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\fingerprint.py\", line 458, in wrapper\n    out = func(self, *args, **kwargs)\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 2320, in _map_single\n    example = apply_function_on_filtered_inputs(example, i, offset=offset)\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 2220, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 1915, in decorated\n    result = f(decorated_item, *args, **kwargs)\n  File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_3340\\2009910298.py\", line 5, in tokenize_function\nNameError: name 'tokenizer' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3340\\2600106843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenized_datasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    456\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                 )\n\u001b[1;32m--> 458\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m             }\n\u001b[0;32m    460\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    456\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                 )\n\u001b[1;32m--> 458\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m             }\n\u001b[0;32m    460\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2067\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync_result\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2068\u001b[1;33m                         \u001b[0mtransformed_shards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masync_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2070\u001b[0m             assert (\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=False, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02c2785d-6c88-478a-888e-d68e63d0a0f3",
    "_uuid": "672f5761-986c-47b6-b889-5d4136e07992",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.828588Z",
     "iopub.status.idle": "2022-06-10T01:54:34.829465Z",
     "shell.execute_reply": "2022-06-10T01:54:34.82919Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.829157Z"
    },
    "id": "5iMY3sAc1pH2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36aec882-44cd-436f-9f5d-c03556ba0c64",
    "_uuid": "11b1105f-9fa0-4b93-836c-4479d2a9f456",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.831043Z",
     "iopub.status.idle": "2022-06-10T01:54:34.831941Z",
     "shell.execute_reply": "2022-06-10T01:54:34.83166Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.83163Z"
    },
    "id": "mmQ5ZHoB1ph-",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder,\n",
    "    # we could add padding if the model supported it instead of this drop,\n",
    "    # you can customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a95c241c-8426-4e41-81f7-48593e64a8b3",
    "_uuid": "91771e77-c27d-48d3-a752-b7fa424fe270",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.833472Z",
     "iopub.status.idle": "2022-06-10T01:54:34.834278Z",
     "shell.execute_reply": "2022-06-10T01:54:34.834027Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.833998Z"
    },
    "id": "Nq9h4jZ91scA",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "2caeeb1e-5287-4172-e34f-58615a09661f"
   },
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "831aacab-e8be-4155-af80-844e47e033dd",
    "_uuid": "6924ddf9-7bd3-45f5-9c4d-9a8ce7d75f85",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.835845Z",
     "iopub.status.idle": "2022-06-10T01:54:34.836663Z",
     "shell.execute_reply": "2022-06-10T01:54:34.836411Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.836382Z"
    },
    "id": "dxuI-0Zr1usa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, XLNetLMHeadModel\n",
    "\n",
    "config = AutoConfig(\n",
    "    n_layer=12,\n",
    "    d_model=768,\n",
    "    n_head=12,\n",
    "    d_inner=4096,\n",
    "    dropout=0.1,\n",
    "    dropatt=0.1,\n",
    "    bi_data=True,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    cutoffs=[]\n",
    ")\n",
    "model = XLNetLMHeadModel(config=config)\n",
    "# model = XLNetLMHeadModel.from_pretrained(\"../input/xlnet-gpu/my-xlnet-model/checkpoint-485280\")\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "155401c7-6b4a-41d1-9c8f-e32b7ae39cfb",
    "_uuid": "3d3a44a1-375c-4518-86e0-0715ed377011",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.838144Z",
     "iopub.status.idle": "2022-06-10T01:54:34.838955Z",
     "shell.execute_reply": "2022-06-10T01:54:34.838696Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.838667Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f75d7c43-9bb2-43a5-9cf5-500c38acd9c4",
    "_uuid": "bb244ddf-b4b8-45d8-933c-f4eeebb54e13",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.840534Z",
     "iopub.status.idle": "2022-06-10T01:54:34.841024Z",
     "shell.execute_reply": "2022-06-10T01:54:34.84085Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.840831Z"
    },
    "id": "t6QNWqG51xJE",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForPermutationLanguageModeling\n",
    "data_collator = DataCollatorForPermutationLanguageModeling(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b11f5d2-009b-499b-a9da-9b9d9d7d7074",
    "_uuid": "db42134e-5b27-4d6c-875e-abcec5c1e01a",
    "execution": {
     "iopub.execute_input": "2022-06-13T22:17:14.592763Z",
     "iopub.status.busy": "2022-06-13T22:17:14.592279Z",
     "iopub.status.idle": "2022-06-13T22:17:23.408868Z",
     "shell.execute_reply": "2022-06-13T22:17:23.407757Z",
     "shell.execute_reply.started": "2022-06-13T22:17:14.592668Z"
    },
    "id": "UGOouW_W12pZ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\"\"\"\n",
    "Batch size                  8192 x\n",
    "Learning rate               4e-4 x\n",
    "Number of steps             500K x\n",
    "Warmup steps                40.000 x\n",
    "Learning rate decay         linear x\n",
    "Adam epsilon                1e-6 x\n",
    "Weigth decay                0.01 x\n",
    "\"\"\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my-xlnet-model\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    num_train_epochs=16,\n",
    "    per_device_train_batch_size=8192,\n",
    "    learning_rate=4e-4,\n",
    "    weight_decay=0.01,\n",
    "    max_steps=500_000,\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=40_000,\n",
    "    save_steps=1011,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66462012-2e90-43b9-a25c-b0780e351cd0",
    "_uuid": "c14e692b-9dd1-44b9-bb33-832d8f62b224",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.844349Z",
     "iopub.status.idle": "2022-06-10T01:54:34.844934Z",
     "shell.execute_reply": "2022-06-10T01:54:34.844764Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.844745Z"
    },
    "id": "WLHDcEGa141_",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20fe974f-ccf5-401a-8d25-77d9453fd86e",
    "_uuid": "29d93818-c9c1-4489-bcfb-f7f7b30a22ec",
    "execution": {
     "iopub.status.busy": "2022-06-10T01:54:34.846062Z",
     "iopub.status.idle": "2022-06-10T01:54:34.846467Z",
     "shell.execute_reply": "2022-06-10T01:54:34.846267Z",
     "shell.execute_reply.started": "2022-06-10T01:54:34.846251Z"
    },
    "id": "H3kBBZP61-VW",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# trainer.train(model_path=\"../input/xlnet-gpu/my-xlnet-model/checkpoint-485280\")\n",
    "trainer.save_model(\"my-xlnet-model\")\n",
    "tokenizer.save_pretrained(\"my-xlnet-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of train and evaluate loss.\n",
    "loss_history = {'train_loss':[], 'eval_loss':[]}\n",
    "\n",
    "# Keep track of train and evaluate perplexity.\n",
    "# This is a metric useful to track for language models.\n",
    "perplexity_history = {'train_perplexity':[], 'eval_perplexity':[]}\n",
    "\n",
    "# Loop through each log history.\n",
    "for log_history in trainer.state.log_history:\n",
    "    if 'loss' in log_history.keys():\n",
    "        # Deal with trianing loss.\n",
    "        loss_history['train_loss'].append(log_history['loss'])\n",
    "        perplexity_history['train_perplexity'].append(math.exp(log_history['loss']))\n",
    "    \n",
    "    elif 'eval_loss' in log_history.keys():\n",
    "        # Deal with eval loss.\n",
    "        loss_history['eval_loss'].append(log_history['eval_loss'])\n",
    "        perplexity_history['eval_perplexity'].append(math.exp(log_history['eval_loss']))\n",
    "\n",
    "# Plot Losses.\n",
    "plot_dict(loss_history, start_step=training_args.logging_steps, \n",
    "          step_size=training_args.logging_steps, use_title='Loss', \n",
    "          use_xlabel='Train Steps', use_ylabel='Values', magnify=2)\n",
    "\n",
    "print()\n",
    "\n",
    "# Plot Perplexities.\n",
    "plot_dict(perplexity_history, start_step=training_args.logging_steps, \n",
    "          step_size=training_args.logging_steps, use_title='Perplexity', \n",
    "          use_xlabel='Train Steps', use_ylabel='Values', magnify=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
